{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df22bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Import library with current code functions\n",
    "sys.path.append(os.path.join(\"..\", \"lib\"))\n",
    "import video_adjuster_functions as vid_adj_fun, general_functions as gf, files_paths as fp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e282e857-9796-4e49-99ab-f87d44092a4d",
   "metadata": {},
   "source": [
    "# Defining variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbd5295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan the folder and save the list of csv\n",
    "FILE_LIST_TO_NORMALIZE = gf.find_files_in_all_subdirectories([fp.DATASET_YT, fp.DATASET_LOCAL], fp.VD_FEATURES_L2)\n",
    "\n",
    "# Filter witch videos has the 'VD_FEATURES_L2.CSV' file and delete then from the list\n",
    "FILE_LIST_TO_NORMALIZE_FILTERED = [feature_file for feature_file in FILE_LIST_TO_NORMALIZE if not os.path.exists(os.path.join(os.path.dirname(feature_file), fp.VD_FEATURES_L3))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f67554a",
   "metadata": {},
   "source": [
    "## Normalize each frame of each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f8a8232",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_start = '0'\n",
    "features_end = '67'\n",
    "normalization_parameter = [[0, 16], 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcbefcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000071\\VD_FEATURES_L2.CSV\n",
      "2 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000072\\VD_FEATURES_L2.CSV\n",
      "3 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000073\\VD_FEATURES_L2.CSV\n",
      "4 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000074\\VD_FEATURES_L2.CSV\n",
      "5 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000075\\VD_FEATURES_L2.CSV\n",
      "6 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000076\\VD_FEATURES_L2.CSV\n",
      "7 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000077\\VD_FEATURES_L2.CSV\n",
      "8 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000078\\VD_FEATURES_L2.CSV\n",
      "9 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000079\\VD_FEATURES_L2.CSV\n",
      "10 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000080\\VD_FEATURES_L2.CSV\n",
      "11 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000081\\VD_FEATURES_L2.CSV\n",
      "12 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000082\\VD_FEATURES_L2.CSV\n",
      "13 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000083\\VD_FEATURES_L2.CSV\n",
      "14 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000084\\VD_FEATURES_L2.CSV\n",
      "15 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000085\\VD_FEATURES_L2.CSV\n",
      "16 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000086\\VD_FEATURES_L2.CSV\n",
      "17 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000087\\VD_FEATURES_L2.CSV\n",
      "18 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000088\\VD_FEATURES_L2.CSV\n",
      "19 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000089\\VD_FEATURES_L2.CSV\n",
      "20 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000090\\VD_FEATURES_L2.CSV\n",
      "21 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000091\\VD_FEATURES_L2.CSV\n",
      "22 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000092\\VD_FEATURES_L2.CSV\n",
      "23 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000093\\VD_FEATURES_L2.CSV\n",
      "24 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000094\\VD_FEATURES_L2.CSV\n",
      "25 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000095\\VD_FEATURES_L2.CSV\n",
      "26 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000096\\VD_FEATURES_L2.CSV\n",
      "27 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000097\\VD_FEATURES_L2.CSV\n",
      "28 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000098\\VD_FEATURES_L2.CSV\n",
      "29 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000099\\VD_FEATURES_L2.CSV\n",
      "30 of 30: Starting to process ..\\Dataset\\DD-Local\\VD_D_0000000100\\VD_FEATURES_L2.CSV\n"
     ]
    }
   ],
   "source": [
    "landmark_smoother = vid_adj_fun.LandmarkSmoother()\n",
    "\n",
    "for i, current_path_location in enumerate(FILE_LIST_TO_NORMALIZE_FILTERED):\n",
    "\n",
    "    print(f\"{i+1} of {len(FILE_LIST_TO_NORMALIZE_FILTERED)}: Starting to process {current_path_location}\")\n",
    "\n",
    "    landmarks_CSV = pd.read_csv(current_path_location)\n",
    "    landmarks_0_to_66 = landmarks_CSV.loc[:, features_start:features_end]\n",
    "    \n",
    "    normalized_landmarks = []\n",
    "    for _, row in landmarks_0_to_66.iterrows():\n",
    "        landmarks_list = [list(ast.literal_eval(coord)) for coord in row]\n",
    "        \n",
    "        # Apply normalizations\n",
    "        scale_factor, z_normalized = vid_adj_fun.z_normalization(landmarks_list, normalization_parameter[0], normalization_parameter[1])\n",
    "        roll_normalized = vid_adj_fun.roll_normalization(z_normalized)\n",
    "        normalized_landmarks.append(z_normalized)\n",
    "    \n",
    "    # Convert each landmark position into a tuple\n",
    "    normalized_landmarks_to_tuple = [[tuple(inner) for inner in outer] for outer in normalized_landmarks]\n",
    "    df_normalized_landmarks = pd.DataFrame(normalized_landmarks_to_tuple)\n",
    "    \n",
    "    # Concatenate left_columns with df_normalized_landmarks along the columns\n",
    "    left_columns = landmarks_CSV.loc[:, 'video_id':'instance_ref']\n",
    "    #angle_columns = landmarks_CSV.loc[:, 'rot_x':'rot_z']\n",
    "\n",
    "    df_result = pd.concat([left_columns, df_normalized_landmarks], axis=1)\n",
    "    \n",
    "    output_path = os.path.join(os.path.dirname(current_path_location), fp.VD_FEATURES_L3)\n",
    "\n",
    "    df_result.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio-signals-dataset_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
